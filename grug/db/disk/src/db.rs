#[cfg(feature = "metrics")]
use grug_types::MetricsIterExt;
use {
    crate::{DbError, DbResult},
    grug_app::{Commitment, Db},
    grug_types::{Batch, Buffer, Hash256, HashExt, Op, Order, Record, Shared, Storage},
    parking_lot::{ArcRwLockReadGuard, RawRwLock},
    rocksdb::{ColumnFamily, DB, IteratorMode, Options, ReadOptions, WriteBatch},
    std::{collections::BTreeMap, marker::PhantomData, ops::Bound, path::Path, sync::Arc},
};

/// We use three column families (CFs) for storing data.
/// The default family is used for metadata. Currently the only metadata we have
/// is the latest version.
pub const CF_NAME_DEFAULT: &str = "default";

/// The preimage column family maps key hashes to raw keys. This is necessary
/// for generating ICS-23 compatible Merkle proofs.
#[cfg(feature = "ibc")]
pub const CF_NAME_PREIMAGES: &str = "preimages";

/// The state commitment (SC) family stores Merkle tree nodes, which hold hashed
/// key-value pair data. We use this CF for deriving the Merkle root hash for the
/// state (used in consensus) and generating Merkle proofs (used in light clients).
pub const CF_NAME_STATE_COMMITMENT: &str = "state_commitment";

/// The state storage (SS) family stores raw, prehash key-value pair data.
/// When performing normal read/write/remove/scan interactions, we use this CF.
pub const CF_NAME_STATE_STORAGE: &str = "state_storage";

/// Storage key for the latest version.
pub const LATEST_VERSION_KEY: &[u8] = b"latest_version";

#[cfg(feature = "metrics")]
pub const DISK_DB_LABEL: &str = "grug.db.disk.duration";

/// The base storage primitive.
///
/// Its main feature is the separation of state storage (SS) and state commitment
/// (SC). Specifically, SS stores _prehash_ key-value pairs (KV pairs), while SC
/// stores _hashed_ KV pairs in a Merkle tree data structure. SS is used for
/// normal read/write access to the state, while SC is used for deriving Merkle
/// root hashes for the state (used by nodes to reach consensus) and generate
/// Merkle proofs for data in the state (used by light clients, such as in iBC).
///
/// The separation of SS and SC was first conceived by the Cosmos SDK core team
/// in ADR-040:
/// <https://github.com/cosmos/cosmos-sdk/blob/main/docs/architecture/adr-040-storage-and-smt-state-commitments.md>
/// and later refined in ADR-065:
/// <https://github.com/cosmos/cosmos-sdk/blob/main/docs/architecture/adr-065-store-v2.md>.
/// It was first pushed to production use by Sei, marketed as SeiDB:
/// <https://blog.sei.io/sei-db-the-numbers/>
///
/// Our design mostly resembles Sei's with the differences being that:
/// - we use a binary Jellyfish Merkle tree (JMT) instead of IAVL;
/// - we store JMT data in a RocksDB instance, instead of using memory map (mmap);
/// - we don't have asynchronous commit;
/// - we don't store snapshots or use a WAL to recover the latest state.
///
/// These differences are not because we don't agree with Sei's approach...
/// it's just because we're having here is sort of a quick hack and we don't
/// have time to look into those advanced features yet. We will keep experimenting
/// and maybe our implementation will converge with Sei's some time later.
pub struct DiskDb<T> {
    /// Data in the database.
    pub(crate) data: Shared<Data>,
    /// Data staged to, but not yet, be committed to the database.
    pending: Shared<Option<PendingData>>,
    /// The commitment scheme.
    _commitment: PhantomData<T>,
}

#[derive(Debug)]
pub(crate) struct Data {
    /// Represents an on-disk RocksDB instance.
    pub(crate) db: DB,
    /// Portion of the state storage that is critical to the chain's performance,
    /// loaded into memory. Reading these data doesn't need to touch the disk.
    priority_data: Option<PriorityData>,
}

#[derive(Debug)]
struct PriorityData {
    min: Vec<u8>, // inclusive
    max: Vec<u8>, // exclusive
    records: BTreeMap<Vec<u8>, Vec<u8>>,
}

#[derive(Debug)]
struct PendingData {
    version: u64,
    state_commitment: Batch,
    state_storage: Batch,
}

impl<T> DiskDb<T> {
    /// Create a DiskDb instance by opening a physical RocksDB instance.
    pub fn open<P>(data_dir: P) -> DbResult<Self>
    where
        P: AsRef<Path>,
    {
        Self::open_with_priority(data_dir, None::<(&[u8], &[u8])>)
    }

    /// Create a DiskDb instance by opening a physical RocksDB instance,
    /// optionally with a priority range. Records within the range will be
    /// loaded into memory for better performance. The range's lower bound is
    /// inclusive, the upper bound is exclusive.
    pub fn open_with_priority<P, B>(data_dir: P, priority_range: Option<(B, B)>) -> DbResult<Self>
    where
        P: AsRef<Path>,
        B: AsRef<[u8]>,
    {
        let db = DB::open_cf(&new_db_options(), data_dir, [
            CF_NAME_DEFAULT,
            #[cfg(feature = "ibc")]
            CF_NAME_PREIMAGES,
            CF_NAME_STATE_STORAGE,
            CF_NAME_STATE_COMMITMENT,
        ])?;

        // If `priority_range` is specified, load the data in that range into memory.
        let priority_data = priority_range.map(|(min, max)| {
            #[cfg(feature = "tracing")]
            let mut size = 0;

            let cf = cf_state_storage(&db);
            let opts = new_read_options(Some(min.as_ref()), Some(max.as_ref()));
            let records = db
                .iterator_cf_opt(&cf, opts, IteratorMode::Start)
                .map(|item| {
                    let (k, v) = item.unwrap_or_else(|err| {
                        panic!("failed to load record for priority data: {err}");
                    });

                    #[cfg(feature = "tracing")]
                    {
                        size += k.len() + v.len();
                    }

                    (k.to_vec(), v.to_vec())
                })
                .collect::<BTreeMap<_, _>>();

            #[cfg(feature = "tracing")]
            {
                tracing::info!(num_records = records.len(), size, "Loaded priority data");
            }

            PriorityData {
                min: min.as_ref().to_vec(),
                max: max.as_ref().to_vec(),
                records,
            }
        });

        Ok(Self {
            data: Shared::new(Data { db, priority_data }),
            pending: Shared::new(None),
            _commitment: PhantomData,
        })
    }
}

impl<T> Clone for DiskDb<T> {
    fn clone(&self) -> Self {
        Self {
            data: self.data.clone(),
            pending: self.pending.clone(),
            _commitment: PhantomData,
        }
    }
}

impl<T> Db for DiskDb<T>
where
    T: Commitment,
{
    type Error = DbError;
    type Proof = T::Proof;
    type StateCommitment = StateCommitment;
    type StateStorage = StateStorage;

    fn state_commitment(&self) -> StateCommitment {
        StateCommitment::new(&self.data)
    }

    fn state_storage_with_comment(
        &self,
        version: Option<u64>,
        #[cfg_attr(
            not(any(feature = "tracing", feature = "metrics")),
            allow(unused_variables)
        )]
        comment: &'static str,
    ) -> DbResult<StateStorage> {
        // If version is unspecified, use the latest version. Otherwise, make
        // sure it's no newer than the latest version.
        if let Some(version) = version {
            // Read the latest version.
            // If it doesn't exist, this means not even a single batch has been
            // written yet (e.g. during `InitChain`). In this case just use zero.
            let latest_version = self.latest_version().unwrap_or(0);
            if version != latest_version {
                return Err(DbError::incorrect_version(version, latest_version));
            }
        }

        Ok(StateStorage::new(&self.data, comment))
    }

    fn latest_version(&self) -> Option<u64> {
        self.data.read_with(|inner| {
            let bytes = inner
                .db
                .get_cf(&cf_default(&inner.db), LATEST_VERSION_KEY)
                .unwrap_or_else(|err| {
                    panic!("failed to read latest version from default column family: {err}");
                })?
                .try_into()
                .unwrap_or_else(|bytes: Vec<u8>| {
                    panic!("latest version is of incorrect length: {}", bytes.len());
                });

            Some(u64::from_le_bytes(bytes))
        })
    }

    fn oldest_version(&self) -> Option<u64> {
        // This database isn't archival, meaning it only keeps the most recent
        // version, so the oldest available version is the same as the latest version.
        self.latest_version()
    }

    fn root_hash(&self, version: Option<u64>) -> DbResult<Option<Hash256>> {
        let version = version.unwrap_or_else(|| self.latest_version().unwrap_or(0));
        Ok(T::root_hash(&self.state_commitment(), version)?)
    }

    fn prove(&self, key: &[u8], version: Option<u64>) -> DbResult<Self::Proof> {
        let version = version.unwrap_or_else(|| self.latest_version().unwrap_or(0));
        Ok(T::prove(&self.state_commitment(), key.hash256(), version)?)
    }

    fn flush_but_not_commit(&self, batch: Batch) -> DbResult<(u64, Option<Hash256>)> {
        #[cfg(feature = "metrics")]
        let duration = std::time::Instant::now();

        // A write batch must not already exist. If it does, it means a batch
        // has been flushed, but not committed, then a next batch is flusehd,
        // which indicates some error in the ABCI app's logic.
        if self.pending.read_access().is_some() {
            return Err(DbError::pending_data_already_set());
        }

        let (old_version, new_version) = match self.latest_version() {
            // An old version exist.
            // Set the new version to be the old version plus one
            Some(v) => (v, v + 1),
            // The old version doesn't exist. This means not a first batch has
            // been flushed yet. In this case, we set the new version to be zero.
            // This is necessary to ensure that DB version always matches the
            // block height.
            None => (0, 0),
        };

        // Commit hashed KVs to state commitment.
        // The DB writes here are kept in the in-memory `PendingData`.
        let mut buffer = Buffer::new(
            self.state_commitment(),
            None,
            "disk_db/state_commitment/flush_but_not_commit",
        );

        let root_hash = T::apply(&mut buffer, old_version, new_version, &batch)?;
        let (_, pending) = buffer.disassemble();

        *(self.pending.write_access()) = Some(PendingData {
            version: new_version,
            state_commitment: pending,
            state_storage: batch,
        });

        #[cfg(feature = "metrics")]
        {
            metrics::histogram!(DISK_DB_LABEL, "operation" => "flush_but_not_commit")
                .record(duration.elapsed().as_secs_f64());
        }

        Ok((new_version, root_hash))
    }

    fn commit(&self) -> DbResult<()> {
        #[cfg(feature = "metrics")]
        let duration = std::time::Instant::now();

        let pending = self
            .pending
            .write_access()
            .take()
            .ok_or(DbError::pending_data_not_set())?;

        #[cfg(feature = "tracing")]
        {
            tracing::debug!(commit = "commit", "Acquiring write-lock on data");
        }

        self.data.write_with(|mut data| {
            #[cfg(feature = "tracing")]
            {
                tracing::debug!(commit = "commit", "Acquired write-lock on data");
            }

            // If priority data exists, apply the change set to it.
            if let Some(priority) = &mut data.priority_data {
                for (k, op) in pending.state_storage.range::<[u8], _>((
                    Bound::Included(priority.min.as_slice()),
                    Bound::Excluded(priority.max.as_slice()),
                )) {
                    if let Op::Insert(v) = op {
                        priority.records.insert(k.clone(), v.clone());
                    } else {
                        priority.records.remove(k);
                    }
                }
            }

            // Now, prepare the write batch that will be written to RocksDB.
            let mut batch = WriteBatch::default();

            // Set the new version (note: use little endian)
            let cf = cf_default(&data.db);
            batch.put_cf(&cf, LATEST_VERSION_KEY, pending.version.to_le_bytes());

            // Writes in state commitment
            let cf = cf_state_commitment(&data.db);
            for (key, op) in pending.state_commitment {
                if let Op::Insert(value) = op {
                    batch.put_cf(&cf, key, value);
                } else {
                    batch.delete_cf(&cf, key);
                }
            }

            // Writes in preimages (note: don't forget to delete key hashes that
            // are deleted in state storage - see Zellic audit).
            // This is only necessary if the `ibc` feature is enabled.
            #[cfg(feature = "ibc")]
            {
                let cf = cf_preimages(&data.db);
                for (key, op) in &pending.state_storage {
                    let key_hash = key.hash256();
                    if let Op::Insert(_) = op {
                        batch.put_cf(&cf, key_hash, key);
                    } else {
                        batch.delete_cf(&cf, key_hash);
                    }
                }
            }

            // Writes in state storage
            let cf = cf_state_storage(&data.db);
            for (key, op) in pending.state_storage {
                if let Op::Insert(value) = op {
                    batch.put_cf(&cf, key, value);
                } else {
                    batch.delete_cf(&cf, key);
                }
            }

            data.db.write(batch)
        })?;

        #[cfg(feature = "tracing")]
        {
            tracing::debug!(commit = "commit", "Released write-lock on data");
        }

        #[cfg(feature = "metrics")]
        {
            metrics::histogram!(DISK_DB_LABEL, "operation" => "commit")
                .record(duration.elapsed().as_secs_f64());
        }

        Ok(())
    }

    fn prune(&self, up_to_version: u64) -> DbResult<()> {
        #[cfg(feature = "tracing")]
        {
            tracing::info!(up_to_version, "Pruning database");
        }

        #[cfg(feature = "metrics")]
        let duration = std::time::Instant::now();

        // Prune state commitment.
        let mut buffer = Buffer::new(
            self.state_commitment(),
            None,
            "disk_db/state_commitment/prune",
        );

        T::prune(&mut buffer, up_to_version)?;

        let (_, pending) = buffer.disassemble();

        self.data.write_with(|data| {
            let mut batch = WriteBatch::default();

            let cf = cf_state_commitment(&data.db);
            for (key, op) in pending {
                if let Op::Insert(value) = op {
                    batch.put_cf(&cf, key, value);
                } else {
                    batch.delete_cf(&cf, key);
                }
            }

            data.db.write(batch)
        })?;

        #[cfg(feature = "metrics")]
        {
            metrics::histogram!(DISK_DB_LABEL, "operation" => "prune")
                .record(duration.elapsed().as_secs_f64());
        }

        Ok(())
    }
}

// ----------------------------- state commitment ------------------------------

#[derive(Debug, Clone)]
pub struct StateCommitment {
    data: Arc<ArcRwLockReadGuard<RawRwLock, Data>>,
}

impl StateCommitment {
    fn new(data: &Shared<Data>) -> Self {
        #[cfg(feature = "tracing")]
        {
            tracing::debug!(comment = "commitment", "Acquiring read-lock on data");
        }

        let data = data.static_read_access();

        #[cfg(feature = "tracing")]
        {
            tracing::debug!(comment = "commitment", "Acquired read-lock on data");
        }

        Self {
            data: Arc::new(data),
        }
    }
}

impl Storage for StateCommitment {
    fn read(&self, key: &[u8]) -> Option<Vec<u8>> {
        let cf = cf_state_commitment(&self.data.db);
        self.data.db.get_cf(&cf, key).unwrap_or_else(|err| {
            panic!("failed to read from state commitment: {err}");
        })
    }

    fn scan<'a>(
        &'a self,
        min: Option<&[u8]>,
        max: Option<&[u8]>,
        order: Order,
    ) -> Box<dyn Iterator<Item = Record> + 'a> {
        let opts = new_read_options(min, max);
        let mode = into_iterator_mode(order);
        let iter = self
            .data
            .db
            .iterator_cf_opt(&cf_state_commitment(&self.data.db), opts, mode)
            .map(|item| {
                let (k, v) = item.unwrap_or_else(|err| {
                    panic!("failed to iterate in state commitment: {err}");
                });
                (k.to_vec(), v.to_vec())
            });
        Box::new(iter)
    }

    fn scan_keys<'a>(
        &'a self,
        min: Option<&[u8]>,
        max: Option<&[u8]>,
        order: Order,
    ) -> Box<dyn Iterator<Item = Vec<u8>> + 'a> {
        let opts = new_read_options(min, max);
        let mode = into_iterator_mode(order);
        let iter = self
            .data
            .db
            .iterator_cf_opt(&cf_state_commitment(&self.data.db), opts, mode)
            .map(|item| {
                let (k, _) = item.unwrap_or_else(|err| {
                    panic!("failed to iterate in state commitment: {err}");
                });
                k.to_vec()
            });
        Box::new(iter)
    }

    fn scan_values<'a>(
        &'a self,
        min: Option<&[u8]>,
        max: Option<&[u8]>,
        order: Order,
    ) -> Box<dyn Iterator<Item = Vec<u8>> + 'a> {
        let opts = new_read_options(min, max);
        let mode = into_iterator_mode(order);
        let iter = self
            .data
            .db
            .iterator_cf_opt(&cf_state_commitment(&self.data.db), opts, mode)
            .map(|item| {
                let (_, v) = item.unwrap_or_else(|err| {
                    panic!("failed to iterate in state commitment: {err}");
                });
                v.to_vec()
            });
        Box::new(iter)
    }

    fn write(&mut self, _key: &[u8], _value: &[u8]) {
        unreachable!("write function called on read-only storage");
    }

    fn remove(&mut self, _key: &[u8]) {
        unreachable!("write function called on read-only storage");
    }

    fn remove_range(&mut self, _min: Option<&[u8]>, _max: Option<&[u8]>) {
        unreachable!("write function called on read-only storage");
    }
}

#[cfg(feature = "tracing")]
impl Drop for StateCommitment {
    fn drop(&mut self) {
        tracing::debug!(comment = "commitment", "Released read-lock on data");
    }
}

// ------------------------------- state storage -------------------------------

#[derive(Clone, Debug)]
pub struct StateStorage {
    data: Arc<ArcRwLockReadGuard<RawRwLock, Data>>,
    #[cfg(any(feature = "tracing", feature = "metrics"))]
    comment: &'static str,
}

impl StateStorage {
    fn new(
        data: &Shared<Data>,
        #[cfg_attr(
            not(any(feature = "tracing", feature = "metrics")),
            allow(unused_variables)
        )]
        comment: &'static str,
    ) -> Self {
        #[cfg(feature = "tracing")]
        {
            tracing::debug!(comment, "Acquiring read-lock on data");
        }

        let data = data.static_read_access();

        #[cfg(feature = "tracing")]
        {
            tracing::debug!(comment, "Acquired read-lock on data");
        }

        Self {
            data: Arc::new(data),
            #[cfg(any(feature = "tracing", feature = "metrics"))]
            comment,
        }
    }

    fn create_iterator<'a>(
        &'a self,
        min: Option<&[u8]>,
        max: Option<&[u8]>,
        order: Order,
    ) -> Box<dyn Iterator<Item = Record> + 'a> {
        // If priority data exists, and the iterator range completely falls
        // within the priority range, then create a priority iterator.
        // Note: `min` and `data.min` are both inclusive; `max` and `data.max`
        // are both exclusive.
        if let (Some(data), Some(min), Some(max)) = (&self.data.priority_data, min, max) {
            if data.min.as_slice() <= min && max <= data.max.as_slice() {
                return data.records.scan(Some(min), Some(max), order);
            }
        }

        let opts = new_read_options(min, max);
        let mode = into_iterator_mode(order);
        let iter = self
            .data
            .db
            .iterator_cf_opt(&cf_state_storage(&self.data.db), opts, mode)
            .map(|item| {
                let (k, v) = item.unwrap_or_else(|err| {
                    panic!("failed to iterate in state storage: {err}");
                });
                (k.to_vec(), v.to_vec())
            });

        #[cfg(feature = "metrics")]
        let iter = iter.with_metrics(DISK_DB_LABEL, [
            ("operation", "next"),
            ("comment", self.comment),
        ]);

        Box::new(iter)
    }
}

impl Storage for StateStorage {
    fn read(&self, key: &[u8]) -> Option<Vec<u8>> {
        #[cfg(feature = "metrics")]
        let duration = std::time::Instant::now();

        // If the key falls in the priority data range, read the value from
        // priority data, without accessing the disk.
        // Note: `min` is inclusive, while `max` is exclusive.
        if let Some(data) = &self.data.priority_data {
            if data.min.as_slice() <= key && key < data.max.as_slice() {
                return data.records.get(key).cloned();
            }
        }

        let opts = new_read_options(None, None);
        let value = self
            .data
            .db
            .get_cf_opt(&cf_state_storage(&self.data.db), key, &opts)
            .unwrap_or_else(|err| {
                panic!("failed to read from state storage: {err}");
            });

        #[cfg(feature = "metrics")]
        {
            metrics::histogram!(DISK_DB_LABEL, "operation" => "read", "comment" => self.comment)
                .record(duration.elapsed().as_secs_f64());
        }

        value
    }

    fn scan<'a>(
        &'a self,
        min: Option<&[u8]>,
        max: Option<&[u8]>,
        order: Order,
    ) -> Box<dyn Iterator<Item = Record> + 'a> {
        #[cfg(feature = "metrics")]
        let duration = std::time::Instant::now();

        let iter = self.create_iterator(min, max, order);

        #[cfg(feature = "metrics")]
        {
            metrics::histogram!(DISK_DB_LABEL, "operation" => "scan", "comment" => self.comment)
                .record(duration.elapsed().as_secs_f64());
        }

        iter
    }

    fn scan_keys<'a>(
        &'a self,
        min: Option<&[u8]>,
        max: Option<&[u8]>,
        order: Order,
    ) -> Box<dyn Iterator<Item = Vec<u8>> + 'a> {
        #[cfg(feature = "metrics")]
        let duration = std::time::Instant::now();

        let iter = self.create_iterator(min, max, order).map(|(k, _)| k);

        #[cfg(feature = "metrics")]
        {
            metrics::histogram!(DISK_DB_LABEL, "operation" => "scan_keys", "comment" => self.comment)
                .record(duration.elapsed().as_secs_f64());
        }

        Box::new(iter)
    }

    fn scan_values<'a>(
        &'a self,
        min: Option<&[u8]>,
        max: Option<&[u8]>,
        order: Order,
    ) -> Box<dyn Iterator<Item = Vec<u8>> + 'a> {
        #[cfg(feature = "metrics")]
        let duration = std::time::Instant::now();

        let iter = self.create_iterator(min, max, order).map(|(_, v)| v);

        #[cfg(feature = "metrics")]
        {
            metrics::histogram!(DISK_DB_LABEL, "operation" => "scan_values", "comment" => self.comment)
                .record(duration.elapsed().as_secs_f64());
        }

        Box::new(iter)
    }

    fn write(&mut self, _key: &[u8], _value: &[u8]) {
        unreachable!("write function called on read-only storage");
    }

    fn remove(&mut self, _key: &[u8]) {
        unreachable!("write function called on read-only storage");
    }

    fn remove_range(&mut self, _min: Option<&[u8]>, _max: Option<&[u8]>) {
        unreachable!("write function called on read-only storage");
    }
}

#[cfg(feature = "tracing")]
impl Drop for StateStorage {
    fn drop(&mut self) {
        tracing::debug!(comment = self.comment, "Released read-lock on data");
    }
}

// ---------------------------------- helpers ----------------------------------

#[inline]
fn into_iterator_mode(order: Order) -> IteratorMode<'static> {
    match order {
        Order::Ascending => IteratorMode::Start,
        Order::Descending => IteratorMode::End,
    }
}

// TODO: rocksdb tuning? see:
// https://github.com/sei-protocol/sei-db/blob/main/ss/rocksdb/opts.go#L29-L65
// https://github.com/turbofish-org/merk/blob/develop/src/merk/mod.rs#L84-L102
pub fn new_db_options() -> Options {
    let mut opts = Options::default();
    opts.create_if_missing(true);
    opts.create_missing_column_families(true);
    opts
}

pub(crate) fn new_read_options(
    iterate_lower_bound: Option<&[u8]>,
    iterate_upper_bound: Option<&[u8]>,
) -> ReadOptions {
    let mut opts = ReadOptions::default();
    if let Some(bound) = iterate_lower_bound {
        opts.set_iterate_lower_bound(bound);
    }
    if let Some(bound) = iterate_upper_bound {
        opts.set_iterate_upper_bound(bound);
    }
    opts
}

pub fn cf_default(db: &DB) -> &ColumnFamily {
    db.cf_handle(CF_NAME_DEFAULT).unwrap_or_else(|| {
        panic!("failed to find default column family");
    })
}

#[cfg(feature = "ibc")]
pub(crate) fn cf_preimages(db: &DB) -> &ColumnFamily {
    db.cf_handle(CF_NAME_PREIMAGES).unwrap_or_else(|| {
        panic!("failed to find default column family");
    })
}

pub fn cf_state_storage(db: &DB) -> &ColumnFamily {
    db.cf_handle(CF_NAME_STATE_STORAGE).unwrap_or_else(|| {
        panic!("failed to find state storage column family");
    })
}

pub fn cf_state_commitment(db: &DB) -> &ColumnFamily {
    db.cf_handle(CF_NAME_STATE_COMMITMENT).unwrap_or_else(|| {
        panic!("failed to find state commitment column family");
    })
}

// ------------------------ tests using JMT commitment -------------------------

#[cfg(test)]
mod tests_jmt {
    use {
        crate::DiskDb,
        grug_app::Db,
        grug_jmt::{MerkleTree, verify_proof},
        grug_types::{
            Batch, Hash256, HashExt, MembershipProof, NonMembershipProof, Op, Order, Proof,
            ProofNode, Storage,
        },
        hex_literal::hex,
        temp_rocksdb::TempDataDir,
    };

    // Using the same test case as in our rust-rocksdb fork:
    // https://github.com/left-curve/rust-rocksdb/blob/v0.21.0-cw/tests/test_timestamp.rs#L150
    //
    // hash(donald)  = 01000001...
    // hash(jake)    = 11001101...
    // hash(joe)     = 01111000...
    // hash(larry)   = 00001101...
    // hash(pumpkin) = 11111111...

    // The tree at version 1 should look like:
    //
    //           root
    //         ┌──┴──┐
    //         0     jake
    //      ┌──┴──┐
    //    larry   01
    //         ┌──┴──┐
    //      donald  joe
    //
    // hash_00
    // = hash(01 | hash("larry") | hash("engineer"))
    // = hash(01 | 0d098b1c0162939e05719f059f0f844ed989472e9e6a53283a00fe92127ac27f | 7826b958b79c70626801b880405eb5111557dadceb2fee2b1ed69a18eed0c6dc)
    // = 01d2b46c3dd0180a5e8236137b4ada8ae6c9ca7c8799ecf7932d1320c9dfbf3b
    //
    // hash_010
    // = hash(01 | hash("donald") | hash("trump"))
    // = hash(01 | 4138cfbc5d36f31e8ae09ef4044bb88c0c9c6f289a6a1c27b335a99d1d8dc86f | a60a52382d7077712def2a69eda3ba309b19598944aa459ce418ae53b7fb5d58)
    // = 8fb3cdb9c15244dc8b7f701bb08640389dcde92a3b85277348ca1ec839d2a575
    //
    // hash_011
    // = hash(01 | hash("joe") | hash("biden"))
    // = hash(01 | 78675cc176081372c43abab3ea9fb70c74381eb02dc6e93fb6d44d161da6eeb3 | 0631a609edb7c79f3a051b935ddb0927818ebd03964a4d18f316d2dadf216894)
    // = hash(3b640fe6cffebfa7c2ba388b66aa3a4978c2221799ef9316e059eed2e656511a)
    //
    // hash_01
    // = hash(00 | 8fb3cdb9c15244dc8b7f701bb08640389dcde92a3b85277348ca1ec839d2a575 | 3b640fe6cffebfa7c2ba388b66aa3a4978c2221799ef9316e059eed2e656511a)
    // = 248f2dfa7cd94e3856e5a6978e500e6d9528837cd0c64187b937455f8d865baf
    //
    // hash_0
    // = hash(00 | 01d2b46c3dd0180a5e8236137b4ada8ae6c9ca7c8799ecf7932d1320c9dfbf3b | 248f2dfa7cd94e3856e5a6978e500e6d9528837cd0c64187b937455f8d865baf)
    // = 4d28a7511b5df59d1cdab1ace2314ba10f4637d0b51cac24ad0dbf199f7333ad
    //
    // hash_1
    // = hash(01 | hash("jake") | hash("shepherd"))
    // = hash(01 | cdf30c6b345276278bedc7bcedd9d5582f5b8e0c1dd858f46ef4ea231f92731d | def3735d7a0d2696775d6d72f379e4536c4d9e3cd6367f27a0bcb7f40d4558fb)
    // = 8358fe5d68c2d969c72b67ccffef68e2bf3b2edb200c0a7731e9bf131be11394
    //
    // root_hash
    // = hash(00 | 4d28a7511b5df59d1cdab1ace2314ba10f4637d0b51cac24ad0dbf199f7333ad | 8358fe5d68c2d969c72b67ccffef68e2bf3b2edb200c0a7731e9bf131be11394)
    // = 1712a8d4c9896a8cadb4e13592bd9e2713a16d0bf5572a8bf540eb568cb30b64
    mod v0 {
        use super::*;

        pub const ROOT_HASH: Hash256 = Hash256::from_inner(hex!(
            "1712a8d4c9896a8cadb4e13592bd9e2713a16d0bf5572a8bf540eb568cb30b64"
        ));
        pub const HASH_0: Hash256 = Hash256::from_inner(hex!(
            "4d28a7511b5df59d1cdab1ace2314ba10f4637d0b51cac24ad0dbf199f7333ad"
        ));
        pub const HASH_00: Hash256 = Hash256::from_inner(hex!(
            "01d2b46c3dd0180a5e8236137b4ada8ae6c9ca7c8799ecf7932d1320c9dfbf3b"
        ));
        pub const HASH_01: Hash256 = Hash256::from_inner(hex!(
            "248f2dfa7cd94e3856e5a6978e500e6d9528837cd0c64187b937455f8d865baf"
        ));
        pub const HASH_010: Hash256 = Hash256::from_inner(hex!(
            "8fb3cdb9c15244dc8b7f701bb08640389dcde92a3b85277348ca1ec839d2a575"
        ));
        pub const HASH_011: Hash256 = Hash256::from_inner(hex!(
            "3b640fe6cffebfa7c2ba388b66aa3a4978c2221799ef9316e059eed2e656511a"
        ));
        pub const HASH_1: Hash256 = Hash256::from_inner(hex!(
            "8358fe5d68c2d969c72b67ccffef68e2bf3b2edb200c0a7731e9bf131be11394"
        ));
    }

    // The tree at version 2 should look like:
    //
    //            root
    //         ┌───┴───┐
    //         0       1
    //      ┌──┴──┐    └──┐
    //   larry  donald    11
    //                ┌───┴───┐
    //              jake   pumpkin
    //
    // hash_00
    // = 01d2b46c3dd0180a5e8236137b4ada8ae6c9ca7c8799ecf7932d1320c9dfbf3b (same as v1)
    //
    // hash_01
    // = hash(01 | hash("donald") | hash("duck"))
    // = hash(01 | 4138cfbc5d36f31e8ae09ef4044bb88c0c9c6f289a6a1c27b335a99d1d8dc86f | 2d2370db2447ff8cf4f3accd68c85aa119a9c893effd200a9b69176e9fc5eb98)
    // = 44cb87f51dbe89d482329a5cc71fadf6758d3c3f7a46b8e03efbc9354e4b5be7
    //
    // hash_0
    // = hash(00 | 01d2b46c3dd0180a5e8236137b4ada8ae6c9ca7c8799ecf7932d1320c9dfbf3b | 44cb87f51dbe89d482329a5cc71fadf6758d3c3f7a46b8e03efbc9354e4b5be7)
    // = 7ce76869da6e1ff26f873924e6667e131761ef9075aebd6bba7c48663696f402
    //
    // hash_110
    // = 8358fe5d68c2d969c72b67ccffef68e2bf3b2edb200c0a7731e9bf131be11394 (same as in v1)
    //
    // hash_111
    // = hash(01 | hash("pumpkin") | hash("cat"))
    // = hash(01 | ff48e511e1638fc379cb75de1c28fe2016051b167f9aa8cac3dd86c6f4787539 | 77af778b51abd4a3c51c5ddd97204a9c3ae614ebccb75a606c3b6865aed6744e)
    // = a2cb2e0c6a5b3717d5355d1e8d046f305f7bd9730cf94434b51063209664f9c6
    //
    // hash_11
    // = hash(00 | 8358fe5d68c2d969c72b67ccffef68e2bf3b2edb200c0a7731e9bf131be11394 | a2cb2e0c6a5b3717d5355d1e8d046f305f7bd9730cf94434b51063209664f9c6)
    // = 1fd4c7d63c6349b827d1af289d9870f923d0be6ecbb6b91c2f42d81ac7b45a51
    //
    // hash_1
    // = hash(00 | 0000000000000000000000000000000000000000000000000000000000000000 | 1fd4c7d63c6349b827d1af289d9870f923d0be6ecbb6b91c2f42d81ac7b45a51)
    // = 9445f09716426120318220f103d9925c8a73155cf561ed4440b3d1fdc1f1153f
    //
    // root_hash
    // = hash(00 | 7ce76869da6e1ff26f873924e6667e131761ef9075aebd6bba7c48663696f402 | 9445f09716426120318220f103d9925c8a73155cf561ed4440b3d1fdc1f1153f)
    // = 05c5d1c5e433ed85c4b5c42d4da7adf6d204d3c1af37cac316f47b042c154eb4
    mod v1 {
        use super::*;

        pub const ROOT_HASH: Hash256 = Hash256::from_inner(hex!(
            "05c5d1c5e433ed85c4b5c42d4da7adf6d204d3c1af37cac316f47b042c154eb4"
        ));
        pub const HASH_0: Hash256 = Hash256::from_inner(hex!(
            "7ce76869da6e1ff26f873924e6667e131761ef9075aebd6bba7c48663696f402"
        ));
        pub const HASH_00: Hash256 = Hash256::from_inner(hex!(
            "01d2b46c3dd0180a5e8236137b4ada8ae6c9ca7c8799ecf7932d1320c9dfbf3b"
        ));
        pub const HASH_01: Hash256 = Hash256::from_inner(hex!(
            "44cb87f51dbe89d482329a5cc71fadf6758d3c3f7a46b8e03efbc9354e4b5be7"
        ));
        pub const HASH_1: Hash256 = Hash256::from_inner(hex!(
            "9445f09716426120318220f103d9925c8a73155cf561ed4440b3d1fdc1f1153f"
        ));
        pub const HASH_110: Hash256 = Hash256::from_inner(hex!(
            "8358fe5d68c2d969c72b67ccffef68e2bf3b2edb200c0a7731e9bf131be11394"
        ));
        pub const HASH_111: Hash256 = Hash256::from_inner(hex!(
            "a2cb2e0c6a5b3717d5355d1e8d046f305f7bd9730cf94434b51063209664f9c6"
        ));
    }

    #[test]
    fn disk_db_works() {
        let path = TempDataDir::new("_grug_disk_db_works");
        let db = DiskDb::<MerkleTree>::open(&path).unwrap();

        // Version 0
        {
            // Write a batch.
            let batch = Batch::from([
                (b"donald".to_vec(), Op::Insert(b"trump".to_vec())),
                (b"jake".to_vec(), Op::Insert(b"shepherd".to_vec())),
                (b"joe".to_vec(), Op::Insert(b"biden".to_vec())),
                (b"larry".to_vec(), Op::Insert(b"engineer".to_vec())),
            ]);
            let (version, root_hash) = db.flush_and_commit(batch).unwrap();
            assert_eq!(version, 0);
            assert_eq!(root_hash, Some(v0::ROOT_HASH));

            // Read single records.
            for (key, value) in [
                ("donald", Some("trump")),
                ("jake", Some("shepherd")),
                ("joe", Some("biden")),
                ("larry", Some("engineer")),
                ("pumpkin", None),
            ] {
                let found_value = db
                    .state_storage(Some(0))
                    .unwrap()
                    .read(key.as_bytes())
                    .map(|bz| String::from_utf8(bz).unwrap());
                assert_eq!(found_value.as_deref(), value);
            }

            // Iterator records.
            for ((found_key, found_value), (key, value)) in db
                .state_storage(Some(version))
                .unwrap()
                .scan(None, None, Order::Ascending)
                .zip([
                    ("donald", "trump"),
                    ("jake", "shepherd"),
                    ("joe", "biden"),
                    ("larry", "engineer"),
                ])
            {
                assert_eq!(found_key, key.as_bytes());
                assert_eq!(found_value, value.as_bytes());
            }
        }

        // Version 1
        {
            // Write a batch.
            let batch = Batch::from([
                (b"donald".to_vec(), Op::Insert(b"duck".to_vec())),
                (b"joe".to_vec(), Op::Delete),
                (b"pumpkin".to_vec(), Op::Insert(b"cat".to_vec())),
            ]);
            let (version, root_hash) = db.flush_and_commit(batch).unwrap();
            assert_eq!(version, 1);
            assert_eq!(root_hash, Some(v1::ROOT_HASH));

            // Read single records.
            for (key, value) in [
                ("donald", Some("duck")),
                ("jake", Some("shepherd")),
                ("joe", None),
                ("larry", Some("engineer")),
                ("pumpkin", Some("cat")),
            ] {
                let found_value = db
                    .state_storage(Some(1))
                    .unwrap()
                    .read(key.as_bytes())
                    .map(|bz| String::from_utf8(bz).unwrap());
                assert_eq!(found_value.as_deref(), value);
            }

            // Iterator records.
            for ((found_key, found_value), (key, value)) in db
                .state_storage(Some(version))
                .unwrap()
                .scan(None, None, Order::Ascending)
                .zip([
                    ("donald", "duck"),
                    ("jake", "shepherd"),
                    ("larry", "engineer"),
                    ("pumpkin", "cat"),
                ])
            {
                assert_eq!(found_key, key.as_bytes());
                assert_eq!(found_value, value.as_bytes());
            }
        }

        // Try generating merkle proofs at the two versions, respectively; also
        // verify the proofs.
        for (version, key, value, proof) in [
            (
                0,
                "donald",
                Some("trump"),
                Proof::Membership(MembershipProof {
                    sibling_hashes: vec![Some(v0::HASH_011), Some(v0::HASH_00), Some(v0::HASH_1)],
                }),
            ),
            (
                0,
                "jake",
                Some("shepherd"),
                Proof::Membership(MembershipProof {
                    sibling_hashes: vec![Some(v0::HASH_0)],
                }),
            ),
            (
                0,
                "joe",
                Some("biden"),
                Proof::Membership(MembershipProof {
                    sibling_hashes: vec![Some(v0::HASH_010), Some(v0::HASH_00), Some(v0::HASH_1)],
                }),
            ),
            (
                0,
                "larry",
                Some("engineer"),
                Proof::Membership(MembershipProof {
                    sibling_hashes: vec![Some(v0::HASH_01), Some(v0::HASH_1)],
                }),
            ),
            (
                0,
                "pumpkin",
                None,
                Proof::NonMembership(NonMembershipProof {
                    node: ProofNode::Leaf {
                        key_hash: "jake".hash256(),
                        value_hash: "shepherd".hash256(),
                    },
                    sibling_hashes: vec![Some(v0::HASH_0)],
                }),
            ),
            (
                1,
                "donald",
                Some("duck"),
                Proof::Membership(MembershipProof {
                    sibling_hashes: vec![Some(v1::HASH_00), Some(v1::HASH_1)],
                }),
            ),
            (
                1,
                "jake",
                Some("shepherd"),
                Proof::Membership(MembershipProof {
                    sibling_hashes: vec![Some(v1::HASH_111), None, Some(v1::HASH_0)],
                }),
            ),
            (
                1,
                "joe",
                None,
                Proof::NonMembership(NonMembershipProof {
                    node: ProofNode::Leaf {
                        key_hash: "donald".hash256(),
                        value_hash: "duck".hash256(),
                    },
                    sibling_hashes: vec![Some(v1::HASH_00), Some(v1::HASH_1)],
                }),
            ),
            (
                1,
                "larry",
                Some("engineer"),
                Proof::Membership(MembershipProof {
                    sibling_hashes: vec![Some(v1::HASH_01), Some(v1::HASH_1)],
                }),
            ),
            (
                1,
                "pumpkin",
                Some("cat"),
                Proof::Membership(MembershipProof {
                    sibling_hashes: vec![Some(v1::HASH_110), None, Some(v1::HASH_0)],
                }),
            ),
        ] {
            let found_proof = db.prove(key.as_bytes(), Some(version)).unwrap();
            assert_eq!(found_proof, proof);

            let root_hash = match version {
                0 => v0::ROOT_HASH,
                1 => v1::ROOT_HASH,
                _ => unreachable!(),
            };
            assert!(
                verify_proof(
                    root_hash,
                    key.as_bytes().hash256(),
                    value.map(|v| v.hash256()),
                    &found_proof,
                )
                .is_ok()
            );
        }
    }

    #[test]
    fn disk_db_pruning_works() {
        let path = TempDataDir::new("_grug_disk_db_pruning_works");
        let db = DiskDb::<MerkleTree>::open(&path).unwrap();

        // Apply a few batches. Same test data as used in the JMT test.
        for batch in [
            // v0
            Batch::from([
                (b"r".to_vec(), Op::Insert(b"foo".to_vec())),
                (b"m".to_vec(), Op::Insert(b"bar".to_vec())),
                (b"L".to_vec(), Op::Insert(b"fuzz".to_vec())),
                (b"a".to_vec(), Op::Insert(b"buzz".to_vec())),
            ]),
            // v1
            Batch::from([(b"m".to_vec(), Op::Delete)]),
            // v2
            Batch::from([(b"r".to_vec(), Op::Delete)]),
            // v3
            Batch::from([(b"L".to_vec(), Op::Delete)]),
            // v4
            Batch::from([(b"a".to_vec(), Op::Delete)]),
        ] {
            db.flush_and_commit(batch).unwrap();
        }

        // Prune up to v3.
        // This deletes version 0-2. v3 is now the oldest available version.
        db.prune(3).unwrap();

        // Attempt access the state under versions 0..=2, should fail.
        for version in 0..=2 {
            // Request state storage. Should fail with `DbError::VersionTooOld`.
            assert!(db.state_storage(Some(version)).is_err_and(|err| {
                err.to_string()
                    .contains("doesn't equal the current version (4)")
            }));

            // Prove a key. Should fail when attempting to load the root node of
            // that version.
            assert!(db.prove(b"a", Some(version)).is_err_and(|err| {
                err.to_string()
                    .contains("data not found! type: grug_jmt::node::Node")
            }));
        }

        // State storage doesn't exist for version 3, because we only keep the
        // latest version, but proving at version 3 should work.
        // Proof doesn't work for version 4 though, because the tree is empty.
        // We can't proof anything if the tree is empty...
        {
            assert!(db.state_storage(Some(3)).is_err());
            assert!(db.prove(b"a", Some(3)).is_ok());
        }

        // Doing the same under version 5 (newer than the latest version) should fail.
        {
            assert!(db.state_storage(Some(5)).is_err_and(|err| {
                err.to_string()
                    .contains("doesn't equal the current version (4)")
            }));

            assert!(db.prove(b"a", Some(5)).is_err_and(|err| {
                err.to_string()
                    .contains("data not found! type: grug_jmt::node::Node")
            }));
        }
    }
}

// ----------------------- tests using simple commitment -----------------------

#[cfg(test)]
mod tests_simple {
    use {super::*, grug_app::SimpleCommitment, grug_types::hash, temp_rocksdb::TempDataDir};

    // sha256(6 | donald | 1 | 5 | trump | 4 | jake | 1 | 8 | shepherd | 3 | joe | 1 | 5 | biden | 5 | larry | 1 | 8 | engineer)
    // = sha256(0006646f6e616c640100057472756d7000046a616b65010008736865706865726400036a6f65010005626964656e00056c61727279010008656e67696e656572)
    const V0_HASH: Hash256 =
        hash!("be33ce9316ee2af84f037db3a9d6d01bd2e61557ae7859d4d02138b08e6cc9f9");

    // sha256(6 | donald | 1 | 4 | duck | 3 | joe | 0 | 7 | pumpkin | 1 | 3 | cat)
    // = sha256(0006646f6e616c640100046475636b00036a6f6500000770756d706b696e010003636174)
    const V1_HASH: Hash256 =
        hash!("27fc5226bce75bd7750366ee3ddcf35f2d8daafb9f8e14f855f673e1e6fcb021");

    #[test]
    fn disk_db_lite_works() {
        let path = TempDataDir::new("_grug_disk_db_lite_works");
        let db = DiskDb::<SimpleCommitment>::open(&path).unwrap();

        // Write a 1st batch.
        {
            let batch = Batch::from([
                (b"donald".to_vec(), Op::Insert(b"trump".to_vec())),
                (b"jake".to_vec(), Op::Insert(b"shepherd".to_vec())),
                (b"joe".to_vec(), Op::Insert(b"biden".to_vec())),
                (b"larry".to_vec(), Op::Insert(b"engineer".to_vec())),
            ]);
            let (version, root_hash) = db.flush_and_commit(batch).unwrap();
            assert_eq!(version, 0);
            assert_eq!(root_hash, Some(V0_HASH));

            for (k, v) in [
                ("donald", Some("trump")),
                ("jake", Some("shepherd")),
                ("joe", Some("biden")),
                ("larry", Some("engineer")),
            ] {
                let found_value = db
                    .state_storage(Some(version))
                    .unwrap()
                    .read(k.as_bytes())
                    .map(|v| String::from_utf8(v).unwrap());
                assert_eq!(found_value.as_deref(), v);
            }
        }

        // Write a 2nd batch.
        {
            let batch = Batch::from([
                (b"donald".to_vec(), Op::Insert(b"duck".to_vec())),
                (b"joe".to_vec(), Op::Delete),
                (b"pumpkin".to_vec(), Op::Insert(b"cat".to_vec())),
            ]);
            let (version, root_hash) = db.flush_and_commit(batch).unwrap();
            assert_eq!(version, 1);
            assert_eq!(root_hash, Some(V1_HASH));

            for (k, v) in [
                ("donald", Some("duck")),
                ("jake", Some("shepherd")),
                ("joe", None),
                ("larry", Some("engineer")),
                ("pumpkin", Some("cat")),
            ] {
                let found_value = db
                    .state_storage(Some(version))
                    .unwrap()
                    .read(k.as_bytes())
                    .map(|v| String::from_utf8(v).unwrap());
                assert_eq!(found_value.as_deref(), v);
            }
        }
    }

    #[test]
    fn priority_data() {
        let path = TempDataDir::new("_grug_disk_db_priority_data");

        // First, open the DB _without_ priority data, and write some records.
        let db = DiskDb::<SimpleCommitment>::open(&path).unwrap();

        db.flush_and_commit(Batch::from([
            (b"000".to_vec(), Op::Insert(b"000".to_vec())),
            (b"001".to_vec(), Op::Insert(b"001".to_vec())),
            (b"002".to_vec(), Op::Insert(b"002".to_vec())),
            (b"003".to_vec(), Op::Insert(b"003".to_vec())),
            (b"004".to_vec(), Op::Insert(b"004".to_vec())),
        ]))
        .unwrap();

        // Enusre rockdb max is exclusive.
        db.data.read_with(|data| {
            assert_eq!(
                data.db
                    .iterator_cf_opt(
                        &cf_state_storage(&data.db),
                        new_read_options(Some(b"000"), Some(b"004")),
                        IteratorMode::Start,
                    )
                    .map(|res| {
                        let (k, v) = res.unwrap();
                        (k.to_vec(), v.to_vec())
                    })
                    .collect::<Vec<_>>(),
                [
                    (b"000".to_vec(), b"000".to_vec()),
                    (b"001".to_vec(), b"001".to_vec()),
                    (b"002".to_vec(), b"002".to_vec()),
                    (b"003".to_vec(), b"003".to_vec()),
                ]
            );

            assert_eq!(
                data.db
                    .iterator_cf_opt(
                        &cf_state_storage(&data.db),
                        new_read_options(Some(b"000"), Some(b"005")),
                        IteratorMode::Start,
                    )
                    .map(|res| {
                        let (k, v) = res.unwrap();
                        (k.to_vec(), v.to_vec())
                    })
                    .collect::<Vec<_>>(),
                [
                    (b"000".to_vec(), b"000".to_vec()),
                    (b"001".to_vec(), b"001".to_vec()),
                    (b"002".to_vec(), b"002".to_vec()),
                    (b"003".to_vec(), b"003".to_vec()),
                    (b"004".to_vec(), b"004".to_vec()),
                ]
            );
        });

        drop(db);

        // Open the DB again, _with_ priority data this time.
        let db =
            DiskDb::<SimpleCommitment>::open_with_priority(&path, Some((b"000", b"004"))).unwrap();

        // In order to test the priorty data, we manually delete a key from the db.
        // This is not something that should happen in a normal use case but allows
        // us to test the priority data.
        // Remove the `002` key from the db.
        db.data.write_with(|data| {
            assert_eq!(
                data.db
                    .get_cf_opt(
                        &cf_state_storage(&data.db),
                        b"002",
                        &new_read_options(None, None)
                    )
                    .unwrap()
                    .unwrap(),
                b"002"
            );

            data.db
                .delete_cf(&cf_state_storage(&data.db), b"002")
                .unwrap();

            assert!(
                data.db
                    .get_cf_opt(
                        &cf_state_storage(&data.db),
                        b"002",
                        &new_read_options(None, None)
                    )
                    .unwrap()
                    .is_none()
            );
        });

        let storage = db.state_storage(None).unwrap();

        // We should be able to read `002` from the priority data.
        // This proves we're accessing it from priority data (as expected), not
        // from the underlying rocksdb.
        assert_eq!(storage.read(b"002").unwrap(), b"002");

        // Iterate over the a range included in the priority data
        assert_eq!(
            storage
                .scan_values(Some(b"001"), Some(b"003"), Order::Ascending)
                .collect::<Vec<_>>(),
            [b"001", b"002"]
        );

        // Iterate over the exact range of the priority data
        assert_eq!(
            storage
                .scan_values(Some(b"000"), Some(b"004"), Order::Ascending)
                .collect::<Vec<_>>(),
            [b"000", b"001", b"002", b"003"]
        );

        // Iterate over a range that exceeds the priority data.
        // Data are loaded from disk, key `002` should not be found.
        assert_eq!(
            storage
                .scan_values(Some(b"000"), Some(b"005"), Order::Ascending)
                .collect::<Vec<_>>(),
            [b"000", b"001", b"003", b"004"]
        );
    }

    #[test]
    fn priority_data_new_db() {
        let path = TempDataDir::new("_grug_disk_db_priority_data_new_db");

        // Open a brand new DB with priority data. Should succeed.
        let _db =
            DiskDb::<SimpleCommitment>::open_with_priority(&path, Some((b"000", b"004"))).unwrap();
    }
}

// ------------------------------- deadlock test -------------------------------

/// Reproduction of a deadlock issue we discovered in testnet-3.
///
/// Assume thread 1 represents the HTTPD server, thread 2 represents the ABCI
/// server:
///
/// - Thread 1 serves a query that involves iterateing over an `IndexedMap`.
///   The iterator acquires a read-lock to the `priority_data` map, and holds
///   onto it until the iterator itself is dropped.
/// - Thread 2 receives a `Commit` request from CometBFT. It attempts to acquire
///   a write-lock of `priority_data`.
/// - The iterator in thread 1 advances. Note that in `IndexedMap`, iteration
///   involves first reading an index key from the index map (this uses the
///   iterator's own read-lock), and then read from the primary map. To read
///   from the primary map, the iterator attempts to acquire another read-lock.
///   However, since thread 2 is already waiting for a write lock, according to
///   the fairness rule, thread 1 has to wait after thread 2. Hence, deadlock.
#[cfg(test)]
mod test_deadlock {
    use {
        super::*,
        grug_app::SimpleCommitment,
        grug_storage::{Index, IndexList, IndexedMap, MultiIndex},
        std::time::Duration,
        temp_rocksdb::TempDataDir,
    };

    const PERSONS: IndexedMap<String, String, PersonIndexes> =
        IndexedMap::new("person", PersonIndexes {
            race: MultiIndex::new(|_name, race| race.clone(), "person", "person__race"),
        });

    struct PersonIndexes<'a> {
        pub race: MultiIndex<'a, String, String, String>,
    }

    impl<'a> IndexList<String, String> for PersonIndexes<'a> {
        fn get_indexes(&self) -> Box<dyn Iterator<Item = &'_ dyn Index<String, String>> + '_> {
            let v: [&dyn Index<String, String>; 1] = [&self.race];
            Box::new(v.into_iter())
        }
    }

    #[test]
    fn deadlock_problem() {
        with_timeout(run_deadlock_test, Duration::from_secs(5));
    }

    /// Ensure the execution of a function doesn't take longer than the given timeout.
    fn with_timeout<F>(f: F, timeout: Duration)
    where
        F: FnOnce() + Send + 'static,
    {
        let (tx, rx) = std::sync::mpsc::channel();

        std::thread::spawn(move || {
            f();
            tx.send(()).unwrap();
        });

        rx.recv_timeout(timeout).unwrap();
    }

    fn run_deadlock_test() {
        let path = TempDataDir::new("_grug_disk_db_deadlock_problem");
        let db = DiskDb::<SimpleCommitment>::open_with_priority(
            &path,
            Some(([0], [255])), // Simply use 0..255 as the priority range, so ALL data in the state storage is loaded into priority data.
        )
        .unwrap();

        // Batch 1: write some data into the index map.
        {
            let storage = db.state_storage(None).unwrap();
            let mut buffer = Buffer::new_unnamed(storage, None);

            for (name, race) in [
                ("Ulfric Stormcloak", "Nord"),
                ("General Tullius", "Imperial"),
                ("Kodlak Whitemane", "Nord"),
                ("Savos Aren", "Dark Elf"),
                ("Mercer Frey", "Breton"),
                ("Astrid", "Nord"),
            ] {
                PERSONS
                    .save(&mut buffer, name.to_string(), &race.to_string())
                    .unwrap();
            }

            let (_, batch) = buffer.disassemble();
            db.flush_and_commit(batch).unwrap();
        }

        // Spawn two threads:
        // - a "read thread" that mimics the httpd server;
        // - a "write thread" that mimics the ABCI server.
        std::thread::scope(|s| {
            // Create a thread to iterate through the map.
            let read_thread = s.spawn(|| {
                let storage = db.state_storage(None).unwrap();
                PERSONS
                    .idx
                    .race
                    .prefix("Nord".to_string())
                    .range(&storage, None, None, Order::Ascending) // Deadlock only happens with `range` and `values`, not with `keys`.
                    .map(|res| {
                        // Do the iteration slowly.
                        std::thread::sleep(Duration::from_secs(1));

                        let (name, _race) = res.unwrap();
                        name
                    })
                    .collect::<Vec<_>>()
            });

            // Create another thread to write a new batch.
            let write_thread = s.spawn(|| {
                let storage = db.state_storage(None).unwrap();
                let mut buffer = Buffer::new_unnamed(storage, None);

                for (name, race) in [
                    ("Aela the Huntress", "Nord"),
                    ("Urag gro-Shub", "Orc"),
                    ("Brynjolf", "Nord"),
                    ("Farengar Secret-Fire", "Nord"),
                    ("Balimund", "Nord"),
                    ("Delphine", "Breton"),
                ] {
                    PERSONS
                        .save(&mut buffer, name.to_string(), &race.to_string())
                        .unwrap();
                }

                let (_, batch) = buffer.disassemble();
                db.flush_but_not_commit(batch).unwrap();

                // Wait a second, so that we commit when the read thread is half way
                // through the iteration.
                std::thread::sleep(Duration::from_secs(1));

                db.commit().unwrap();
            });

            let names = read_thread.join().unwrap();
            write_thread.join().unwrap();

            // Names should only include those in batch 1, without those in batch 2.
            assert_eq!(names, ["Astrid", "Kodlak Whitemane", "Ulfric Stormcloak"]);
        });

        // Read again. The records in batch 2 should now be included.
        {
            let storage = db.state_storage(None).unwrap();
            let names = PERSONS
                .idx
                .race
                .prefix("Nord".to_string())
                .range(&storage, None, None, Order::Ascending)
                .map(|res| {
                    let (name, _race) = res.unwrap();
                    name
                })
                .collect::<Vec<_>>();

            assert_eq!(names, [
                "Aela the Huntress",
                "Astrid",
                "Balimund",
                "Brynjolf",
                "Farengar Secret-Fire",
                "Kodlak Whitemane",
                "Ulfric Stormcloak",
            ]);
        }
    }
}
