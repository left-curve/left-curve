# Developer's note: November 10, 2025

This note documents some observations from our testnet-3, and suggetestions for remedying the problems.

An important fact we've neglected until now, is that the DB is used in a multi-thread environment. There are two threads to be considered:

- The ABCI server, which responds to _write_ requests from CometBFT.
- The httpd server, which responds to _read_ requests from users via a GraphQL API.

In the tests we've done so far, we failed to account for the httpd server. The two problems illustrated below stem from this fact.

## Problem 1: race condition

In a previous implementation, `StateStorage` is defined as follows:

```rust
pub struct StateStorage {
    data: Arc<rocksdb::DB>,
}

impl Storage for StateStorage {
    fn read(&self, key: &[u8]) -> Option<Vec<u8>> {
        self.data
            .get_cf_opt(&cf_state_storage(&self.data), key, &ReadOptions::default())
            .unwrap_or_else(|err| {
                panic!("failed to read from state storage: {err}");
            })
    }
}
```

The following problem exists: suppose the httpd server is doing a query that involves multiple reads in the DB; _at the same time_, the ABCI server requests to commit a batch of data into the DB. The following may happen:

1. httpd server reads a first record.[^1] The DB's version (which equals the last finalized block height) is `N` at this time.
2. ABCI server commits a batch of data. The version is incremented to `N+1`.
3. httpd server reads a second record.

As such, part of the query is done using data from block `N`, while the other part uses data from block `N+1`. This is a classic **race condition**, and the query result can be invalid.

### Remedy to problem 1

We decided to add [timestamping](https://github.com/facebook/rocksdb/wiki/User-defined-Timestamp) to the state storage column family. That is, when the httpd server makes a query, it must specify exactly at which version (block height) this query is to be performed at. The DB will then only fetch data at that specific version:

```rust
pub struct StateStorage {
    data: Arc<rocksdb::DB>,
    version: u64, // new!
}

impl Storage for StateStorage {
    fn read(&self, key: &[u8]) -> Option<Vec<u8>> {
        let mut opts = ReadOptions::default();
        opts.set_timestamp(U64Timestamp::from(self.version)); // new!

        self.data
            .get_cf_opt(&cf_state_storage(&self.data), key, &opts)
            .unwrap_or_else(|err| {
                panic!("failed to read from state storage: {err}");
            })
    }
}
```

The drawback of this is **disk usage** and **performance penalty**. If a record is overwritten in multiple versions, the DB will keep all the copies, each suffixed with the version. When reading the record at a specific version, the DB needs to do a binary search to find the appropriate copy. On testnet-3, we observe significant performance degradation over time as the copies accumulate.

To remedy this, we implemented **periodic pruning**, by calling the following function:

```rust
let cf = cf_state_storage(&self.inner.db);
let ts = /* ... */; // set to the latest version minus an offset
db.increase_full_history_ts_low(&cf, ts)?;
```

It's important to note that pruning doesn't take effect immediately. Following the pruning, RocksDB has an internal logic to decide when to perform a **compaction**. Following the compaction, we usually see an improvement in performance. However, we found that while in our internal devnet, the DB automatically compacts roughly once every 30 minutes, it often doesn't compact on the public testnet. We hypothesize that the increased amount of read requests from the httpd server impacts RocksDB's decision on when to compact. We're not able to do a deeper analysis on this as we don't have knowledge on RocksDB's internal compaction logic.

To remedy this, we also implemented **periodic manual compaction** by calling the followng:

```rust
self.inner.db.compact_range_cf(
    &cf_state_storage(&self.inner.db),
    None::<&[u8]>,
    None::<&[u8]>,
);
```

We do not yet understand the impact of doing frequent manual compactions.

All these increases complexity significantly. Additionally, another problem arises when we added **priority data** to the equation.

## Problem 2: priority data deadlock

When creating a `DiskDb` instance, the caller optionally provides a **priority range** of keys `min..max`. Records within this range is loaded into memory. Reading records in this range doesn't need to access the disk. This is good for performance-critical part of the chain's business logic. For Dango, we choose the range corresponding to the DEX contract, and see an immediate 100x improvement in the performance of the end-of-block auction.

The code looks like the following:

```rust
struct Data {
    db: rocksdb::DB,
    priority_data: Option<PriorityData>, // new!
}

struct PriorityData {
    min: Vec<u8>,
    max: Vec<u8>,
    records: RwLock<BTreeMap<Vec<u8>, Vec<u8>>>,
}

pub struct StateStorage {
    data: Arc<Data>, // new!
    version: u64,
}

impl Storage for StateStorage {
    fn read(&self, key: &[u8]) -> Option<Vec<u8>> {
        // If priority data exists and the key is in the range, read from the
        // in-memory map. Otherwise, read from the on-disk DB.
        if let Some(priority_data) = &self.data.priority_data {
            if priority_data.min <= key && key < priority_data.max {
                return priority_data
                  .read()
                  .expect("priority data poisoned")
                  .get(key)
                  .cloned();
            }
        }

        let mut opts = ReadOptions::default();
        opts.set_timestamp(U64Timestamp::from(self.version));

        self.data
            .db
            .get_cf_opt(&cf_state_storage(&self.data.db), key, &opts)
            .unwrap_or_else(|err| {
                panic!("failed to read from state storage: {err}");
            })
    }
}
```

Note here we use an `RwLock` for the records in the priority data. When reading a record, if the key is in the range, we acquire a read-lock. When committing a batch, if there are keys in the range, we acquire a write-lock and insert the records.

Here's the important part: for a query that involves multiple reads, we acquire a read-lock for each read, releasing it immediately after the read is done; instead of acquiring a lock throughout the span of the query.

There are two problems with this. First, **the race condition discussed in the previous section appears again.** The priority data isn't timestamped, meaning we're only keeping the latest version of it. So it's possible that a part of a query uses priority data from block `N`, while the other part uses block `N+1`.

Second, **the two threads (ABCI server and httpd server) may run into a deadlock,** if the httpd server iterates over an `IndexedMap`. For context, when iterating records in an `IndexedMap`, each step involves two actions:

1. Read the next record in **the index map**; the key of this record is the index key, the value is the primary key.
2. Read the value corresponding to the primary key from **the primary map**.

Important: _when the iterator is created, a read-lock over priority data is created, and is held onto until the iterator is dropped; additionally, when reading from the primary map, a read-lock is again acquired for each read._

Now, suppose the ABCI server requests to commit a batch of data while the httpd server is halfway through such an iteration. What happens:

1. The httpd thread creates the iterator, acquiring a read-lock. It holds onto this lock, not releasing it.
2. The ABCI thread attempts to acquire a write-lock. It has to wait, because a read-lock from step (1) is not released.
3. The httpd thread attempts to acquire a read-lock in order to read from the primary map. It has to wait, because the write-lock from step (2) is prioritized due to `RwLock`'s fairness rule.

As such, step (2) waits for step (1), step (1) waits for step (3), a deadlock.

### Remedy to problem 2

After analyzing the problems, we concluded that the fundamental flaw is that **queries are not atomic**. In other words, `StateStorage` acquires a separate read-lock for each read; as such, **the query can be interrupted halfway, if another thread acquires a write-lock at the mean time**. If a query only acquires a single read-lock throughout its entire span, it can't be interrupted, and both problems (race condition and deadlock) are solved. As the race condition problem is solved, we can also remove timestamping, auto-pruning, and auto-compaction from the state storage column family, improving performance and reduce complexity.

The implementation of such a solution, however, is not trivial. One might consider the following:

```rust
struct StateStorage<'a> {
    data: RwLockReadGuard<'a, Data>,
}
```

This however, doesn't work, due to limitations of the `grug_app::Vm` trait:

1. For the WASM VM, the `wasmer` runtime requires all elements in a functional environment to be `Send + 'static`.[^2]
2. The grug app requires the storage instance to be `Clone`.

Problems:

1. Here `StateStorage` is `'a`, not `'static`.
2. `RwLockReadGuard` is not `Send`, for a silly reason: the `std::sync` module uses the operating system's synchronization primitives. On some older platforms (e.g. Windows 7), the read-guard provided by the OS isn't `Send`.[^3] As such, for backward compatility, Rust marks `RwLockReadGuard` as `!Send` for all platforms.[^4]

For problem (1), we can create a self-referencing struct using the [`ouroborous`](https://crates.io/crates/ouroboros) library:

```rust
#[ouroborous::self_referencing]
struct StateStorage {
    data: Arc<Data>,
    #[borrows(data)]
    #[covariant]
    guard: RwLockReadGuard<'this, Data>,
}
```

However, self-referencing structs are not `Clone`. To solve this, we can wrap it inside an `Arc`:

```rust
#[derive(Clone)]
struct StateStorage {
    inner: Arc<StateStorageInner>,
}

#[ouroborous::self_referencing]
struct StateStorageInner {
    data: Arc<Data>,
    #[borrows(data)]
    #[covariant]
    guard: RwLockReadGuard<'this, Data>,
}
```

Finally, for problem (2), instead of the standard library, we use `RwLock` provided by the [`parking_lot`](https://crates.io/crates/parking_lot) library. `parking_lot`'s `RwLock` is pure Rust, so it's not subject to the limitation of the OS, and does implement `Send` for `RwLockReadGuard` (with the `send_guard` feature enabled). It's also faster than `std::sync::RwLock`, at the expense of bigger binary sizes (which isn't a problem in practice, because `tokio` and other popular crates already include a copy of `parking_lot` in their dependency trees).

[^1]: A "record" means a key-value pair.
[^2]: https://github.com/wasmerio/wasmer/blob/v6.1.0/lib/api/src/entities/function/env/mod.rs#L22
[^3]: https://stackoverflow.com/questions/78311670/why-is-send-trait-implemented-for-a-rwlockreadguard-and-rwlockwriteguard-in-rus.
[^4]: https://github.com/rust-lang/rust/blob/1.91.0/library/std/src/sync/poison/rwlock.rs#L128
