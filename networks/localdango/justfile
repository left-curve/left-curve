# Ensure these are consistent with the values in `docker-compose.yml`.
DB_HOST := "db"
DB_PORT := "5432"
DB_USER := "postgres"
DB_NAME := "grug_dev"

# List available recipes
default:
  @just --list

start-dango:
    set -a; source .env; set +a; \
    export PYTH__ACCESS_TOKEN="$PYTH_ACCESS_TOKEN"; \
    INDEXER__CLICKHOUSE__URL="http://localhost:8123" \
    INDEXER__DATABASE__URL="postgres://postgres@localhost:5432/grug_dev" \
    TENDERMINT__RPC_ADDR="http://localhost:26657" \
    cargo run --bin dango start --home ./configs/dango

# Start the localnet
start-inner profiles="":
  #!/usr/bin/env bash
  set -e

  cleanup() {
    local exit_code=$?
    case "$1" in
      "SIGINT")
        echo "Received SIGINT. Shutting down..."
        ;;
      "SIGTERM")
        echo "Received SIGTERM. Shutting down..."
        ;;
      "")
        if [ $exit_code -ne 0 ]; then
          echo "Command failed with exit code $exit_code. Shutting down..."
        fi
        ;;
    esac

    docker compose --profile analytics --profile faucet --profile dango down --remove-orphans
    exit $exit_code
  }

  trap 'cleanup SIGINT' INT
  trap 'cleanup SIGTERM' TERM
  trap 'cleanup' ERR

  docker compose {{profiles}} up -d --wait
  docker compose logs -f

start-src:
      FAUCET_DANGO_ENDPOINT=http://host.docker.internal:8080 \
      DANGO_ABCI_ENDPOINT=tcp://host.docker.internal:26658 \
      just start-inner "--profile analytics --profile faucet"

start:
  just start-inner "--profile analytics --profile faucet --profile dango"

# Stop the localnet
stop:
  docker compose down --remove-orphans

logs:
  docker compose logs -f db -f dango -f cometbft -f clickhouse

# Delete the generate data in order to restart a new localnet from scratch
reset:
  rm -rfv ./configs/dango/data
  rm -rfv ./configs/dango/indexer
  docker volume rm $(docker volume ls -q | grep localdango_ | grep -v localdango_grafana_data)

# Run the development database
run-dev-db:
  docker compose up db

# Check whether the deveopment database is running
check-dev-db:
  docker compose run --rm db pg_isready -h {{DB_HOST}} -p {{DB_PORT}} -U {{DB_USER}}

restore-clickhouse filename:
  docker compose exec clickhouse clickhouse-client --query "RESTORE DATABASE testnet_dango_production FROM File('/var/log/clickhouse-server/backups/{{filename}}')"

# Create the development database
create-dev-db:
  docker compose run --rm db createdb -h {{DB_HOST}} -p {{DB_PORT}} -U {{DB_USER}} {{DB_NAME}}

# Remove the development database
drop-dev-db:
  docker compose run --rm db dropdb -h {{DB_HOST}} -p {{DB_PORT}} -U {{DB_USER}} {{DB_NAME}}

# Migrate the development database
migrate-dev-db:
  sea-orm-cli migrate up -d sql-migration

# Reset the development database
refresh-dev-db:
  sea-orm-cli migrate refresh

# Generate entity from the datatabase for Grug
generate-grug-entity:
  sea-orm-cli generate entity -o sql/src/entity --model-extra-derives 'Default' --ignore-tables 'transfers,accounts,dango_seaql_migrations,grug_seaql_migrations,seaql_migrations'

# Generate entity from the datatabase for Dango
generate-dango-entity:
  sea-orm-cli generate entity -o sql/src/entity --model-extra-derives 'Default' --ignore-tables 'blocks,messages,transactions,events,dango_seaql_migrations,grug_seaql_migrations,seaql_migrations'
